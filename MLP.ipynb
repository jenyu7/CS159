{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID Malignant/Benign  mean radius  mean texture  mean perimeter  \\\n",
      "0      842302                M        17.99         10.38          122.80   \n",
      "1      842517                M        20.57         17.77          132.90   \n",
      "2    84300903                M        19.69         21.25          130.00   \n",
      "3    84348301                M        11.42         20.38           77.58   \n",
      "4    84358402                M        20.29         14.34          135.10   \n",
      "..        ...              ...          ...           ...             ...   \n",
      "564    926424                M        21.56         22.39          142.00   \n",
      "565    926682                M        20.13         28.25          131.20   \n",
      "566    926954                M        16.60         28.08          108.30   \n",
      "567    927241                M        20.60         29.33          140.10   \n",
      "568     92751                B         7.76         24.54           47.92   \n",
      "\n",
      "     mean area  mean smoothness  mean compactness  mean concavity  \\\n",
      "0       1001.0          0.11840           0.27760         0.30010   \n",
      "1       1326.0          0.08474           0.07864         0.08690   \n",
      "2       1203.0          0.10960           0.15990         0.19740   \n",
      "3        386.1          0.14250           0.28390         0.24140   \n",
      "4       1297.0          0.10030           0.13280         0.19800   \n",
      "..         ...              ...               ...             ...   \n",
      "564     1479.0          0.11100           0.11590         0.24390   \n",
      "565     1261.0          0.09780           0.10340         0.14400   \n",
      "566      858.1          0.08455           0.10230         0.09251   \n",
      "567     1265.0          0.11780           0.27700         0.35140   \n",
      "568      181.0          0.05263           0.04362         0.00000   \n",
      "\n",
      "     mean concave pts  ...  worst radius  worst texture  worst perimeter  \\\n",
      "0             0.14710  ...        25.380          17.33           184.60   \n",
      "1             0.07017  ...        24.990          23.41           158.80   \n",
      "2             0.12790  ...        23.570          25.53           152.50   \n",
      "3             0.10520  ...        14.910          26.50            98.87   \n",
      "4             0.10430  ...        22.540          16.67           152.20   \n",
      "..                ...  ...           ...            ...              ...   \n",
      "564           0.13890  ...        25.450          26.40           166.10   \n",
      "565           0.09791  ...        23.690          38.25           155.00   \n",
      "566           0.05302  ...        18.980          34.12           126.70   \n",
      "567           0.15200  ...        25.740          39.42           184.60   \n",
      "568           0.00000  ...         9.456          30.37            59.16   \n",
      "\n",
      "     worst area  worst smoothness  worst compactness  worst concavity  \\\n",
      "0        2019.0           0.16220            0.66560           0.7119   \n",
      "1        1956.0           0.12380            0.18660           0.2416   \n",
      "2        1709.0           0.14440            0.42450           0.4504   \n",
      "3         567.7           0.20980            0.86630           0.6869   \n",
      "4        1575.0           0.13740            0.20500           0.4000   \n",
      "..          ...               ...                ...              ...   \n",
      "564      2027.0           0.14100            0.21130           0.4107   \n",
      "565      1731.0           0.11660            0.19220           0.3215   \n",
      "566      1124.0           0.11390            0.30940           0.3403   \n",
      "567      1821.0           0.16500            0.86810           0.9387   \n",
      "568       268.6           0.08996            0.06444           0.0000   \n",
      "\n",
      "     worst concave pts  worst symmetry  worst frac. dim  \n",
      "0               0.2654          0.4601          0.11890  \n",
      "1               0.1860          0.2750          0.08902  \n",
      "2               0.2430          0.3613          0.08758  \n",
      "3               0.2575          0.6638          0.17300  \n",
      "4               0.1625          0.2364          0.07678  \n",
      "..                 ...             ...              ...  \n",
      "564             0.2216          0.2060          0.07115  \n",
      "565             0.1628          0.2572          0.06637  \n",
      "566             0.1418          0.2218          0.07820  \n",
      "567             0.2650          0.4087          0.12400  \n",
      "568             0.0000          0.2871          0.07039  \n",
      "\n",
      "[569 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"data/wdbc.data\", sep=\",\", header=None)\n",
    "# denote features and improve readability\n",
    "features = [\"radius\", \"texture\", \"perimeter\", \"area\", \"smoothness\", \"compactness\", \"concavity\", \"concave pts\", \n",
    "            \"symmetry\", \"frac dim\"]\n",
    "features3 = []\n",
    "descr = [\"mean\", \"stderr\", \"worst\"]\n",
    "for i in range(30):\n",
    "    if i < 10: \n",
    "        features3.append(descr[0] + \" \"+ features[i%10])\n",
    "    elif i < 20: \n",
    "        features3.append(descr[1] + \" \" + features[i%10])\n",
    "    else: \n",
    "        features3.append(descr[2] + \" \" + features[i%10])\n",
    "data.columns = [\"ID\", \"Malignant/Benign\"] + features3\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define M as 1 and B as 0\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1 + np.exp(-x))\n",
    "\n",
    "def sig_deriv(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def get_inputs(data, features, train_size):\n",
    "    x = data.loc[:,features]\n",
    "    classif = data[\"Malignant/Benign\"]\n",
    "    y = []\n",
    "    for index in classif:\n",
    "        if index == \"B\":\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "    #x = np.asarray(x)\n",
    "    #y = np.asarray(y)\n",
    "    split = int(train_size * len(x))\n",
    "    return x[:split], y[:split], x[split:], y[split:]\n",
    "\n",
    "def verify(x_test, y_test, hidden_dim, pre_hidden_nodes, input_to_hidden_w, post_hidden_nodes, hidden_to_out_w, threshold):\n",
    "    correct = 0\n",
    "    for index in range(x_test.shape[0]):\n",
    "        for node in range(hidden_dim):\n",
    "            pre_hidden_nodes[node] = np.dot(x_test[index], input_to_hidden_w[:, node])\n",
    "            post_hidden_nodes[node] = sigmoid(pre_hidden_nodes[node])\n",
    "        pre_output = np.dot(post_hidden_nodes, hidden_to_out_w)\n",
    "        output = sigmoid(pre_output)\n",
    "\n",
    "        if output > threshold:\n",
    "            output = 1\n",
    "        else:\n",
    "            output = 0\n",
    "        if output == y_test[index]:\n",
    "            correct += 1\n",
    "    return correct/x_test.shape[0]\n",
    "\n",
    "def train(n, rate, x_train, y_train, x_test, y_test): \n",
    "    N = len(x_train)    \n",
    "\n",
    "\n",
    "    input_dim = x_train.shape[1]\n",
    "    hidden_dim = 4\n",
    "    epochs = n\n",
    "    threshold = 0.5\n",
    "    learning_rate = rate\n",
    "\n",
    "    np.random.seed(159)\n",
    "    input_to_hidden_w = np.random.uniform(-1, 1, (input_dim, hidden_dim))\n",
    "    hidden_to_out_w = np.random.uniform(-1, 1, hidden_dim)\n",
    "    pre_hidden_nodes = np.zeros(hidden_dim)\n",
    "    post_hidden_nodes = np.zeros(hidden_dim)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for index in range(N):\n",
    "            for node in range(hidden_dim):\n",
    "                pre_hidden_nodes[node] = np.dot(x_train[index], input_to_hidden_w[:, node])\n",
    "                post_hidden_nodes[node] = sigmoid(pre_hidden_nodes[node])\n",
    "            pre_output = np.dot(post_hidden_nodes, hidden_to_out_w)\n",
    "            output = sigmoid(pre_output)\n",
    "\n",
    "            error = output - y_train[index]\n",
    "\n",
    "            for h in range(hidden_dim):\n",
    "                s = error * sig_deriv(pre_output)\n",
    "                grad_h_o = s * post_hidden_nodes[h]\n",
    "                for i in range(input_dim):\n",
    "                    grad_i_h = x_train[index, i] * s * hidden_to_out_w[h] * sig_deriv(pre_hidden_nodes[h])\n",
    "                    input_to_hidden_w[h] -= learning_rate * grad_i_h\n",
    "                hidden_to_out_w[h] -= learning_rate * grad_h_o\n",
    "\n",
    "    train_err = verify(x_train, y_train, hidden_dim, pre_hidden_nodes, input_to_hidden_w, post_hidden_nodes, hidden_to_out_w,\n",
    "                       threshold)\n",
    "    test_err = verify(x_test, y_test, hidden_dim, pre_hidden_nodes, input_to_hidden_w, post_hidden_nodes, hidden_to_out_w,\n",
    "                      threshold)\n",
    "    return [train_err, test_err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epochs:  20\n",
      "0.6175824175824176 0.7807017543859649\n",
      "Total epochs:  40\n",
      "0.6461538461538462 0.7894736842105263\n",
      "Total epochs:  60\n",
      "0.6527472527472528 0.7982456140350878\n",
      "Total epochs:  80\n",
      "0.6527472527472528 0.7982456140350878\n",
      "Total epochs:  100\n",
      "0.654945054945055 0.8070175438596491\n",
      "Total epochs:  120\n",
      "0.6505494505494506 0.8070175438596491\n",
      "Total epochs:  140\n",
      "0.6373626373626373 0.7894736842105263\n",
      "Total epochs:  160\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  180\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  200\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  220\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  240\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  260\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  280\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  300\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  320\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  340\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  360\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  380\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  400\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  420\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  440\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  460\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  480\n",
      "0.5912087912087912 0.7719298245614035\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = get_inputs(data, ['mean radius', 'mean texture', 'mean smoothness', 'mean compactness',\n",
    "           'mean concavity'], 0.8)\n",
    "train_err, test_err = [], []\n",
    "n_epochs = 500\n",
    "l_rate = 0.01\n",
    "for n in range(20, n_epochs, 20): \n",
    "    print(\"Total epochs: \", n)\n",
    "    err = train(n, l_rate, x_train, y_train, x_test, y_test)\n",
    "    train_err.append(err[0])\n",
    "    test_err.append(err[1])\n",
    "    print(err[0], err[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = np.arange(20, n_epochs, 20)\n",
    "plt.figure()\n",
    "plt.plot(epochs, test_err, label='Testing score')\n",
    "plt.plot(epochs, train_err, label='Training score')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Classification score')\n",
    "plt.title('Score of MLP vs Number of Epochs')\n",
    "plt.legend(loc=0, shadow=True, fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 50 100 150 200 250 300 350 400 450]\n"
     ]
    }
   ],
   "source": [
    "print(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5912087912087912\n",
      "0.7719298245614035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "x_train, y_train, x_test, y_test = get_inputs(data, ['mean radius', 'mean texture', 'mean smoothness', 'mean compactness',\n",
    "       'mean concavity'], 0.8)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(4,), max_iter=30, alpha=1e-4,\n",
    "                    solver='sgd', random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(x_train,y_train)\n",
    "print(mlp.score(x_train, y_train))\n",
    "print(mlp.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trying all 7 mean features** in an effort to improve the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epochs:  50\n",
      "0.5868131868131868 0.7456140350877193\n",
      "Total epochs:  100\n",
      "0.5868131868131868 0.7456140350877193\n",
      "Total epochs:  150\n",
      "0.5868131868131868 0.7456140350877193\n",
      "Total epochs:  200\n",
      "0.5868131868131868 0.7456140350877193\n",
      "Total epochs:  250\n",
      "0.5868131868131868 0.7456140350877193\n",
      "Total epochs:  300\n",
      "0.5868131868131868 0.7456140350877193\n",
      "Total epochs:  350\n",
      "0.5868131868131868 0.7456140350877193\n",
      "Total epochs:  400\n",
      "0.5868131868131868 0.7456140350877193\n",
      "Total epochs:  450\n",
      "0.5868131868131868 0.7456140350877193\n"
     ]
    }
   ],
   "source": [
    "x_train1, y_train1, x_test1, y_test1 = get_inputs(data, [\"mean radius\", \"mean texture\", \"mean perimeter\", \"mean area\", \n",
    "                                                     \"mean smoothness\", \"mean compactness\", \"mean concavity\", \n",
    "                                                     \"mean concave pts\", \"mean symmetry\", \"mean frac. dim\"], 0.8)\n",
    "train_err1, test_err1 = [], []\n",
    "for n in range(50, n_epochs, 50): \n",
    "    print(\"Total epochs: \", n)\n",
    "    err1 = train(n, l_rate, x_train1, y_train1, x_test1, y_test1)\n",
    "    train_err1.append(err[0])\n",
    "    test_err1.append(err[1])\n",
    "    print(err1[0], err1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trying all 30 features** in an effort to improve the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epochs:  10\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  20\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  30\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-4172a5d5f4e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Total epochs: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0merr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_err2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtest_err2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-32f0d386355b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(n, rate, x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                 \u001b[0mpre_hidden_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_to_hidden_w\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m                 \u001b[0mpost_hidden_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_hidden_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mpre_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost_hidden_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_to_out_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train2, y_train2, x_test2, y_test2 = get_inputs(data, data.columns[2:], 0.8)\n",
    "train_err2, test_err2 = [], []\n",
    "for n in range(10, 100, 10): \n",
    "    print(\"Total epochs: \", n)\n",
    "    err2 = train(n, l_rate, x_train2, y_train2, x_test2, y_test2)\n",
    "    train_err2.append(err[0])\n",
    "    test_err2.append(err[1])\n",
    "    print(err2[0], err2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5912087912087912\n",
      "0.7719298245614035\n"
     ]
    }
   ],
   "source": [
    "mlp1 = MLPClassifier(hidden_layer_sizes=(4,), max_iter=100, alpha=1e-4,\n",
    "                    solver='sgd', random_state=1,\n",
    "                    learning_rate_init=.01)\n",
    "\n",
    "mlp1.fit(x_train3, y_train3)\n",
    "print(mlp1.score(x_train3, y_train3))\n",
    "print(mlp1.score(x_test3, y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs1(data, features, train_size):\n",
    "    x = data.loc[:,features]\n",
    "    classif = data[\"Malignant/Benign\"]\n",
    "    y = [ 1 if x == \"M\" else 0 for x in classif]\n",
    "    split = int(train_size * len(x))\n",
    "    return x.head(split).values, y[:split], x.tail(len(x)-split).values, y[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referred to very original paper** in an attempt to improve the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epochs:  0\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  1\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  2\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  3\n",
      "0.5912087912087912 0.7719298245614035\n",
      "Total epochs:  4\n",
      "0.5912087912087912 0.7719298245614035\n"
     ]
    }
   ],
   "source": [
    "#Mean Radius, Mean Perimeter, Mean Fractal, Dimension, Worst Radius, and Worst Area. \n",
    "x_train3, y_train3, x_test3, y_test3 = get_inputs1(data, [\"mean radius\", \"mean perimeter\", \"mean frac. dim\",\n",
    "                                                        \"worst radius\", \"worst area\"], 0.8)\n",
    "train_err3, test_err3 = [], []\n",
    "for n in range(0, 5): \n",
    "    print(\"Total epochs: \", n)\n",
    "    err3 = train(n, l_rate, x_train3, y_train3, x_test3, y_test3)\n",
    "    train_err3.append(err3[0])\n",
    "    test_err3.append(err3[1])\n",
    "    print(err3[0], err3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.228e+02 7.871e-02 2.538e+01 2.019e+03]\n",
      " [2.057e+01 1.329e+02 5.667e-02 2.499e+01 1.956e+03]\n",
      " [1.969e+01 1.300e+02 5.999e-02 2.357e+01 1.709e+03]\n",
      " ...\n",
      " [1.200e+01 7.677e+01 6.104e-02 1.309e+01 5.237e+02]\n",
      " [1.453e+01 9.386e+01 6.121e-02 1.580e+01 7.499e+02]\n",
      " [1.262e+01 8.062e+01 5.826e-02 1.434e+01 6.335e+02]] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0]\n",
      "[[1.338e+01 8.634e+01 6.016e-02 1.505e+01 7.056e+02]\n",
      " [1.163e+01 7.487e+01 6.166e-02 1.312e+01 5.278e+02]\n",
      " [1.321e+01 8.410e+01 5.584e-02 1.435e+01 6.329e+02]\n",
      " [1.300e+01 8.261e+01 5.449e-02 1.434e+01 6.285e+02]\n",
      " [9.755e+00 6.168e+01 5.952e-02 1.067e+01 3.499e+02]\n",
      " [1.708e+01 1.112e+02 6.281e-02 2.296e+01 1.648e+03]\n",
      " [2.742e+01 1.869e+02 5.623e-02 3.604e+01 4.254e+03]\n",
      " [1.440e+01 9.225e+01 5.433e-02 1.540e+01 7.346e+02]\n",
      " [1.160e+01 7.388e+01 5.859e-02 1.277e+01 4.951e+02]\n",
      " [1.317e+01 8.428e+01 5.549e-02 1.490e+01 6.876e+02]\n",
      " [1.324e+01 8.687e+01 6.432e-02 1.544e+01 7.335e+02]\n",
      " [1.314e+01 8.598e+01 6.020e-02 1.480e+01 6.891e+02]\n",
      " [9.668e+00 6.106e+01 6.412e-02 1.115e+01 3.802e+02]\n",
      " [1.760e+01 1.190e+02 7.369e-02 2.157e+01 1.437e+03]\n",
      " [1.162e+01 7.638e+01 7.255e-02 1.336e+01 5.281e+02]\n",
      " [9.667e+00 6.149e+01 6.413e-02 1.114e+01 3.852e+02]\n",
      " [1.204e+01 7.685e+01 5.698e-02 1.360e+01 5.676e+02]\n",
      " [1.492e+01 9.645e+01 5.669e-02 1.718e+01 9.066e+02]\n",
      " [1.227e+01 7.742e+01 5.960e-02 1.345e+01 5.589e+02]\n",
      " [1.088e+01 7.041e+01 6.837e-02 1.194e+01 4.331e+02]\n",
      " [1.283e+01 8.289e+01 5.913e-02 1.409e+01 6.058e+02]\n",
      " [1.420e+01 9.241e+01 6.009e-02 1.645e+01 8.285e+02]\n",
      " [1.390e+01 8.897e+01 5.536e-02 1.514e+01 7.189e+02]\n",
      " [1.149e+01 7.399e+01 6.574e-02 1.240e+01 4.676e+02]\n",
      " [1.625e+01 1.098e+02 6.578e-02 1.739e+01 9.397e+02]\n",
      " [1.216e+01 7.829e+01 6.284e-02 1.334e+01 5.474e+02]\n",
      " [1.390e+01 8.873e+01 5.594e-02 1.641e+01 8.305e+02]\n",
      " [1.347e+01 8.732e+01 6.639e-02 1.483e+01 6.602e+02]\n",
      " [1.370e+01 8.776e+01 6.088e-02 1.496e+01 6.865e+02]\n",
      " [1.573e+01 1.028e+02 6.259e-02 1.701e+01 8.543e+02]\n",
      " [1.245e+01 8.285e+01 7.325e-02 1.378e+01 5.806e+02]\n",
      " [1.464e+01 9.421e+01 5.355e-02 1.646e+01 8.310e+02]\n",
      " [1.944e+01 1.281e+02 6.115e-02 2.396e+01 1.740e+03]\n",
      " [1.168e+01 7.549e+01 6.401e-02 1.332e+01 5.498e+02]\n",
      " [1.669e+01 1.071e+02 5.325e-02 1.918e+01 1.084e+03]\n",
      " [1.225e+01 7.818e+01 5.976e-02 1.417e+01 6.229e+02]\n",
      " [1.785e+01 1.146e+02 5.243e-02 1.982e+01 1.210e+03]\n",
      " [1.801e+01 1.184e+02 6.077e-02 2.153e+01 1.426e+03]\n",
      " [1.246e+01 7.883e+01 6.013e-02 1.319e+01 5.340e+02]\n",
      " [1.316e+01 8.406e+01 5.888e-02 1.450e+01 6.483e+02]\n",
      " [1.487e+01 9.612e+01 5.748e-02 1.601e+01 7.836e+02]\n",
      " [1.265e+01 8.269e+01 6.854e-02 1.438e+01 6.337e+02]\n",
      " [1.247e+01 8.045e+01 6.046e-02 1.406e+01 6.073e+02]\n",
      " [1.849e+01 1.213e+02 6.697e-02 2.275e+01 1.600e+03]\n",
      " [2.059e+01 1.378e+02 6.222e-02 2.386e+01 1.760e+03]\n",
      " [1.504e+01 9.873e+01 6.869e-02 1.676e+01 8.569e+02]\n",
      " [1.382e+01 9.233e+01 7.237e-02 1.601e+01 7.880e+02]\n",
      " [1.254e+01 8.125e+01 6.612e-02 1.357e+01 5.520e+02]\n",
      " [2.309e+01 1.521e+02 5.484e-02 3.079e+01 2.782e+03]\n",
      " [9.268e+00 6.149e+01 9.502e-02 1.028e+01 3.002e+02]\n",
      " [9.676e+00 6.412e+01 9.575e-02 1.060e+01 3.281e+02]\n",
      " [1.222e+01 7.947e+01 6.894e-02 1.316e+01 5.153e+02]\n",
      " [1.106e+01 7.125e+01 7.976e-02 1.169e+01 4.111e+02]\n",
      " [1.630e+01 1.047e+02 5.657e-02 1.732e+01 9.282e+02]\n",
      " [1.546e+01 1.038e+02 7.083e-02 1.711e+01 9.094e+02]\n",
      " [1.174e+01 7.631e+01 6.758e-02 1.245e+01 4.738e+02]\n",
      " [1.481e+01 9.466e+01 5.348e-02 1.561e+01 7.602e+02]\n",
      " [1.340e+01 8.864e+01 7.325e-02 1.641e+01 8.444e+02]\n",
      " [1.458e+01 9.429e+01 5.640e-02 1.676e+01 8.620e+02]\n",
      " [1.505e+01 9.726e+01 5.915e-02 1.758e+01 9.670e+02]\n",
      " [1.134e+01 7.276e+01 6.211e-02 1.247e+01 4.786e+02]\n",
      " [1.831e+01 1.208e+02 5.941e-02 2.186e+01 1.493e+03]\n",
      " [1.989e+01 1.305e+02 6.188e-02 2.373e+01 1.646e+03]\n",
      " [1.288e+01 8.445e+01 7.253e-02 1.505e+01 6.747e+02]\n",
      " [1.275e+01 8.251e+01 6.623e-02 1.445e+01 6.241e+02]\n",
      " [9.295e+00 5.996e+01 7.696e-02 1.057e+01 3.266e+02]\n",
      " [2.463e+01 1.655e+02 6.739e-02 2.992e+01 2.642e+03]\n",
      " [1.126e+01 7.130e+01 6.343e-02 1.193e+01 4.359e+02]\n",
      " [1.371e+01 8.873e+01 6.843e-02 1.511e+01 7.019e+02]\n",
      " [9.847e+00 6.300e+01 6.891e-02 1.124e+01 3.765e+02]\n",
      " [8.571e+00 5.453e+01 7.126e-02 9.473e+00 2.756e+02]\n",
      " [1.346e+01 8.744e+01 6.317e-02 1.535e+01 7.198e+02]\n",
      " [1.234e+01 7.894e+01 5.808e-02 1.361e+01 5.649e+02]\n",
      " [1.394e+01 9.031e+01 6.457e-02 1.462e+01 6.533e+02]\n",
      " [1.207e+01 7.783e+01 6.608e-02 1.345e+01 5.499e+02]\n",
      " [1.175e+01 7.589e+01 6.677e-02 1.350e+01 5.523e+02]\n",
      " [1.167e+01 7.521e+01 6.461e-02 1.335e+01 5.506e+02]\n",
      " [1.368e+01 8.776e+01 6.155e-02 1.585e+01 7.734e+02]\n",
      " [2.047e+01 1.347e+02 5.419e-02 2.323e+01 1.645e+03]\n",
      " [1.096e+01 7.079e+01 6.408e-02 1.162e+01 4.075e+02]\n",
      " [2.055e+01 1.378e+02 6.251e-02 2.430e+01 1.809e+03]\n",
      " [1.427e+01 9.377e+01 5.982e-02 1.529e+01 7.283e+02]\n",
      " [1.169e+01 7.637e+01 7.405e-02 1.298e+01 4.877e+02]\n",
      " [7.729e+00 4.798e+01 7.285e-02 9.077e+00 2.480e+02]\n",
      " [7.691e+00 4.834e+01 7.751e-02 8.678e+00 2.236e+02]\n",
      " [1.154e+01 7.465e+01 6.782e-02 1.226e+01 4.578e+02]\n",
      " [1.447e+01 9.581e+01 6.341e-02 1.622e+01 8.089e+02]\n",
      " [1.474e+01 9.470e+01 5.680e-02 1.651e+01 8.264e+02]\n",
      " [1.321e+01 8.488e+01 5.781e-02 1.437e+01 6.296e+02]\n",
      " [1.387e+01 8.977e+01 6.688e-02 1.505e+01 6.886e+02]\n",
      " [1.362e+01 8.719e+01 5.801e-02 1.535e+01 7.298e+02]\n",
      " [1.032e+01 6.531e+01 6.201e-02 1.125e+01 3.849e+02]\n",
      " [1.026e+01 6.585e+01 6.714e-02 1.083e+01 3.574e+02]\n",
      " [9.683e+00 6.105e+01 6.235e-02 1.093e+01 3.642e+02]\n",
      " [1.082e+01 6.889e+01 6.328e-02 1.303e+01 5.056e+02]\n",
      " [1.086e+01 6.851e+01 5.948e-02 1.166e+01 4.123e+02]\n",
      " [1.113e+01 7.149e+01 6.552e-02 1.202e+01 4.366e+02]\n",
      " [1.277e+01 8.135e+01 5.637e-02 1.387e+01 5.947e+02]\n",
      " [9.333e+00 5.901e+01 6.576e-02 9.845e+00 2.958e+02]\n",
      " [1.288e+01 8.250e+01 5.708e-02 1.389e+01 5.957e+02]\n",
      " [1.029e+01 6.567e+01 6.127e-02 1.084e+01 3.576e+02]\n",
      " [1.016e+01 6.473e+01 6.331e-02 1.065e+01 3.473e+02]\n",
      " [9.423e+00 5.926e+01 6.059e-02 1.049e+01 3.306e+02]\n",
      " [1.459e+01 9.639e+01 6.147e-02 1.548e+01 7.335e+02]\n",
      " [1.151e+01 7.452e+01 6.570e-02 1.248e+01 4.742e+02]\n",
      " [1.405e+01 9.138e+01 6.171e-02 1.530e+01 7.067e+02]\n",
      " [1.120e+01 7.067e+01 5.502e-02 1.192e+01 4.396e+02]\n",
      " [1.522e+01 1.034e+02 7.152e-02 1.752e+01 9.150e+02]\n",
      " [2.092e+01 1.430e+02 6.879e-02 2.429e+01 1.819e+03]\n",
      " [2.156e+01 1.420e+02 5.623e-02 2.545e+01 2.027e+03]\n",
      " [2.013e+01 1.312e+02 5.533e-02 2.369e+01 1.731e+03]\n",
      " [1.660e+01 1.083e+02 5.648e-02 1.898e+01 1.124e+03]\n",
      " [2.060e+01 1.401e+02 7.016e-02 2.574e+01 1.821e+03]\n",
      " [7.760e+00 4.792e+01 5.884e-02 9.456e+00 2.686e+02]] [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0]\n",
      "455 114\n",
      "455 114\n"
     ]
    }
   ],
   "source": [
    "x_train3, y_train3, x_test3, y_test3 = get_inputs1(data, [\"mean radius\", \"mean perimeter\", \"mean frac. dim\",\n",
    "                                                        \"worst radius\", \"worst area\"], 0.8)\n",
    "print(x_train3, y_train3)\n",
    "print(x_test3, y_test3)\n",
    "print(len(x_train3), len(x_test3))\n",
    "print(len(y_train3), len(y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Malignant/Benign</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave pts</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave pts</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst frac. dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID Malignant/Benign  mean radius  mean texture  mean perimeter  \\\n",
       "0      842302                M        17.99         10.38          122.80   \n",
       "1      842517                M        20.57         17.77          132.90   \n",
       "2    84300903                M        19.69         21.25          130.00   \n",
       "3    84348301                M        11.42         20.38           77.58   \n",
       "4    84358402                M        20.29         14.34          135.10   \n",
       "..        ...              ...          ...           ...             ...   \n",
       "564    926424                M        21.56         22.39          142.00   \n",
       "565    926682                M        20.13         28.25          131.20   \n",
       "566    926954                M        16.60         28.08          108.30   \n",
       "567    927241                M        20.60         29.33          140.10   \n",
       "568     92751                B         7.76         24.54           47.92   \n",
       "\n",
       "     mean area  mean smoothness  mean compactness  mean concavity  \\\n",
       "0       1001.0          0.11840           0.27760         0.30010   \n",
       "1       1326.0          0.08474           0.07864         0.08690   \n",
       "2       1203.0          0.10960           0.15990         0.19740   \n",
       "3        386.1          0.14250           0.28390         0.24140   \n",
       "4       1297.0          0.10030           0.13280         0.19800   \n",
       "..         ...              ...               ...             ...   \n",
       "564     1479.0          0.11100           0.11590         0.24390   \n",
       "565     1261.0          0.09780           0.10340         0.14400   \n",
       "566      858.1          0.08455           0.10230         0.09251   \n",
       "567     1265.0          0.11780           0.27700         0.35140   \n",
       "568      181.0          0.05263           0.04362         0.00000   \n",
       "\n",
       "     mean concave pts  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0             0.14710  ...        25.380          17.33           184.60   \n",
       "1             0.07017  ...        24.990          23.41           158.80   \n",
       "2             0.12790  ...        23.570          25.53           152.50   \n",
       "3             0.10520  ...        14.910          26.50            98.87   \n",
       "4             0.10430  ...        22.540          16.67           152.20   \n",
       "..                ...  ...           ...            ...              ...   \n",
       "564           0.13890  ...        25.450          26.40           166.10   \n",
       "565           0.09791  ...        23.690          38.25           155.00   \n",
       "566           0.05302  ...        18.980          34.12           126.70   \n",
       "567           0.15200  ...        25.740          39.42           184.60   \n",
       "568           0.00000  ...         9.456          30.37            59.16   \n",
       "\n",
       "     worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave pts  worst symmetry  worst frac. dim  \n",
       "0               0.2654          0.4601          0.11890  \n",
       "1               0.1860          0.2750          0.08902  \n",
       "2               0.2430          0.3613          0.08758  \n",
       "3               0.2575          0.6638          0.17300  \n",
       "4               0.1625          0.2364          0.07678  \n",
       "..                 ...             ...              ...  \n",
       "564             0.2216          0.2060          0.07115  \n",
       "565             0.1628          0.2572          0.06637  \n",
       "566             0.1418          0.2218          0.07820  \n",
       "567             0.2650          0.4087          0.12400  \n",
       "568             0.0000          0.2871          0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = [\"mean radius\", \"mean perimeter\", \"mean frac. dim\", \"worst radius\", \"worst area\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(): \n",
    "    d2 = np.asmatrix(data.values)\n",
    "    x = d2[:, 2:]\n",
    "    classif = data[\"Malignant/Benign\"]\n",
    "    y = np.asarray([ 1 if x == \"M\" else 0 for x in classif])\n",
    "    return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-fold cross validation** in an attempt to improve the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.627656288608846\n",
      "Test:  0.627656288608846\n",
      "Train:  0.6274799796324585\n",
      "Test:  0.6276710294254154\n",
      "Train:  0.6274559927873251\n",
      "Test:  0.6277701172067369\n",
      "Train:  0.627432041642568\n",
      "Test:  0.6276665114112715\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-ab1a49f3bd23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0merr3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mtraine\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0merr3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mteste\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0merr3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-6b46fd7e93c6>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(n, rate, x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[0mpre_hidden_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_to_hidden_w\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[0mpost_hidden_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_hidden_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[0mpre_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost_hidden_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_to_out_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "X, Y = parse_data()\n",
    "for folds in range(2, 11): \n",
    "    traine, teste = 0, 0\n",
    "    kf = KFold(n_splits=folds)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        #print(train_index, test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        err3 = train(100, l_rate, X_train, Y_train, X_test, Y_test)\n",
    "        traine += err3[0]\n",
    "        teste += err3[1]\n",
    "    print(\"Train: \", traine/folds)\n",
    "    print(\"Test: \", teste/folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = MLPClassifier(hidden_layer_sizes=(4,), max_iter=100, alpha=1e-4,\n",
    "                    solver='sgd', random_state=1,\n",
    "                    learning_rate_init=.01)\n",
    "    mlp2.fit(X_train, Y_train)\n",
    "    print(\"Train: \", mlp2.score(X_train, Y_train))\n",
    "    print(\"Test: \", mlp2.score(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
